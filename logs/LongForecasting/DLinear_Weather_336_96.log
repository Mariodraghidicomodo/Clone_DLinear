Args in experiment:
Namespace(is_training=1, model_id='weather_336_96', model='DLinear', data='custom', root_path='./dataset/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=21, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=16, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use CPU
>>>>>>>start training : weather_336_96_DLinear_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36456
val 5175
test 10444
	iters: 100, epoch: 1 | loss: 0.3628845
	speed: 0.8384s/iter; left time: 19016.1307s
	iters: 200, epoch: 1 | loss: 0.2766471
	speed: 0.0078s/iter; left time: 176.2093s
	iters: 300, epoch: 1 | loss: 0.2645092
	speed: 0.0072s/iter; left time: 162.4748s
	iters: 400, epoch: 1 | loss: 0.6573151
	speed: 0.0074s/iter; left time: 166.2707s
	iters: 500, epoch: 1 | loss: 2.2509141
	speed: 0.0072s/iter; left time: 161.0359s
	iters: 600, epoch: 1 | loss: 0.4184300
	speed: 0.0073s/iter; left time: 161.2850s
	iters: 700, epoch: 1 | loss: 0.3198422
	speed: 0.0072s/iter; left time: 160.0035s
	iters: 800, epoch: 1 | loss: 0.7230432
	speed: 0.0075s/iter; left time: 163.8659s
	iters: 900, epoch: 1 | loss: 0.3246148
	speed: 0.0073s/iter; left time: 159.6235s
	iters: 1000, epoch: 1 | loss: 0.3326199
	speed: 0.0080s/iter; left time: 173.7979s
	iters: 1100, epoch: 1 | loss: 0.4326614
	speed: 0.0076s/iter; left time: 164.5097s
	iters: 1200, epoch: 1 | loss: 0.2627508
	speed: 0.0073s/iter; left time: 156.9426s
	iters: 1300, epoch: 1 | loss: 0.2261406
	speed: 0.0074s/iter; left time: 159.7749s
	iters: 1400, epoch: 1 | loss: 0.2638224
	speed: 0.0077s/iter; left time: 164.8364s
	iters: 1500, epoch: 1 | loss: 0.2920990
	speed: 0.0076s/iter; left time: 162.2775s
	iters: 1600, epoch: 1 | loss: 0.3665574
	speed: 0.0080s/iter; left time: 168.6123s
	iters: 1700, epoch: 1 | loss: 0.2521474
	speed: 0.0072s/iter; left time: 152.8123s
	iters: 1800, epoch: 1 | loss: 0.4449945
	speed: 0.0073s/iter; left time: 152.7655s
	iters: 1900, epoch: 1 | loss: 0.3622516
	speed: 0.0073s/iter; left time: 152.7551s
	iters: 2000, epoch: 1 | loss: 0.3083139
	speed: 0.0080s/iter; left time: 166.8040s
	iters: 2100, epoch: 1 | loss: 0.3281367
	speed: 0.0076s/iter; left time: 157.2476s
	iters: 2200, epoch: 1 | loss: 0.2792698
	speed: 0.0072s/iter; left time: 149.0168s
Epoch: 1 cost time: 99.51424074172974
Epoch: 1, Steps: 2278 | Train Loss: 0.4637915 Vali Loss: 0.4258699 Test Loss: 0.1771051
Validation loss decreased (inf --> 0.425870).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7818858
	speed: 2.2999s/iter; left time: 46924.4922s
	iters: 200, epoch: 2 | loss: 0.3695645
	speed: 0.0080s/iter; left time: 161.7269s
	iters: 300, epoch: 2 | loss: 0.2117906
	speed: 0.0066s/iter; left time: 132.9468s
	iters: 400, epoch: 2 | loss: 0.5039489
	speed: 0.0069s/iter; left time: 137.7959s
	iters: 500, epoch: 2 | loss: 0.2984183
	speed: 0.0067s/iter; left time: 134.5675s
	iters: 600, epoch: 2 | loss: 0.5404892
	speed: 0.0067s/iter; left time: 132.9007s
	iters: 700, epoch: 2 | loss: 2.4672627
	speed: 0.0075s/iter; left time: 148.8878s
	iters: 800, epoch: 2 | loss: 0.2695805
	speed: 0.0095s/iter; left time: 186.3446s
	iters: 900, epoch: 2 | loss: 2.5685451
	speed: 0.0105s/iter; left time: 204.8810s
	iters: 1000, epoch: 2 | loss: 0.2637137
	speed: 0.0075s/iter; left time: 146.7088s
	iters: 1100, epoch: 2 | loss: 0.4440959
	speed: 0.0087s/iter; left time: 169.3220s
	iters: 1200, epoch: 2 | loss: 0.4053720
	speed: 0.0097s/iter; left time: 187.7646s
	iters: 1300, epoch: 2 | loss: 0.2883643
	speed: 0.0078s/iter; left time: 150.5273s
	iters: 1400, epoch: 2 | loss: 0.2908841
	speed: 0.0089s/iter; left time: 170.7356s
	iters: 1500, epoch: 2 | loss: 0.2781036
	speed: 0.0079s/iter; left time: 150.1921s
	iters: 1600, epoch: 2 | loss: 0.2576258
	speed: 0.0084s/iter; left time: 157.9228s
	iters: 1700, epoch: 2 | loss: 0.4485043
	speed: 0.0112s/iter; left time: 210.2844s
	iters: 1800, epoch: 2 | loss: 0.2321666
	speed: 0.0092s/iter; left time: 171.2574s
	iters: 1900, epoch: 2 | loss: 0.3258538
	speed: 0.0081s/iter; left time: 151.5682s
	iters: 2000, epoch: 2 | loss: 0.3714040
	speed: 0.0072s/iter; left time: 132.8496s
	iters: 2100, epoch: 2 | loss: 0.3127016
	speed: 0.0068s/iter; left time: 125.8463s
	iters: 2200, epoch: 2 | loss: 0.3108903
	speed: 0.0110s/iter; left time: 201.5986s
Epoch: 2 cost time: 67.0465133190155
Epoch: 2, Steps: 2278 | Train Loss: 0.4531695 Vali Loss: 0.4239233 Test Loss: 0.1755989
Validation loss decreased (0.425870 --> 0.423923).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2847881
	speed: 1.3800s/iter; left time: 25012.4110s
	iters: 200, epoch: 3 | loss: 0.5639402
	speed: 0.0062s/iter; left time: 111.2005s
	iters: 300, epoch: 3 | loss: 0.3526130
	speed: 0.0062s/iter; left time: 110.5775s
	iters: 400, epoch: 3 | loss: 0.2544597
	speed: 0.0063s/iter; left time: 112.9426s
	iters: 500, epoch: 3 | loss: 0.2975472
	speed: 0.0067s/iter; left time: 118.2107s
	iters: 600, epoch: 3 | loss: 0.4387859
	speed: 0.0070s/iter; left time: 123.4172s
	iters: 700, epoch: 3 | loss: 0.5337220
	speed: 0.0068s/iter; left time: 119.8004s
	iters: 800, epoch: 3 | loss: 0.6447224
	speed: 0.0072s/iter; left time: 125.1424s
	iters: 900, epoch: 3 | loss: 0.5289077
	speed: 0.0070s/iter; left time: 121.1063s
	iters: 1000, epoch: 3 | loss: 0.3046920
	speed: 0.0075s/iter; left time: 129.2192s
	iters: 1100, epoch: 3 | loss: 0.4002889
	speed: 0.0067s/iter; left time: 114.2283s
	iters: 1200, epoch: 3 | loss: 0.6048054
	speed: 0.0065s/iter; left time: 110.7092s
	iters: 1300, epoch: 3 | loss: 0.3817804
	speed: 0.0063s/iter; left time: 107.2310s
	iters: 1400, epoch: 3 | loss: 0.4035893
	speed: 0.0063s/iter; left time: 106.5927s
	iters: 1500, epoch: 3 | loss: 0.2212260
	speed: 0.0065s/iter; left time: 108.7517s
	iters: 1600, epoch: 3 | loss: 0.2607900
	speed: 0.0065s/iter; left time: 108.1115s
	iters: 1700, epoch: 3 | loss: 0.2383615
	speed: 0.0067s/iter; left time: 110.1850s
	iters: 1800, epoch: 3 | loss: 0.3000255
	speed: 0.0070s/iter; left time: 115.0384s
	iters: 1900, epoch: 3 | loss: 0.3557838
	speed: 0.0065s/iter; left time: 106.1528s
	iters: 2000, epoch: 3 | loss: 0.3161082
	speed: 0.0065s/iter; left time: 105.5032s
	iters: 2100, epoch: 3 | loss: 0.3197846
	speed: 0.0062s/iter; left time: 99.4752s
	iters: 2200, epoch: 3 | loss: 0.4255341
	speed: 0.0063s/iter; left time: 101.4993s
Epoch: 3 cost time: 57.85553288459778
Epoch: 3, Steps: 2278 | Train Loss: 0.4516478 Vali Loss: 0.4281661 Test Loss: 0.1729431
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 2.1372814
	speed: 1.3272s/iter; left time: 21031.8365s
	iters: 200, epoch: 4 | loss: 0.3488947
	speed: 0.0077s/iter; left time: 121.5618s
	iters: 300, epoch: 4 | loss: 0.2148647
	speed: 0.0072s/iter; left time: 112.4363s
	iters: 400, epoch: 4 | loss: 0.3862806
	speed: 0.0070s/iter; left time: 109.2890s
	iters: 500, epoch: 4 | loss: 0.2677747
	speed: 0.0072s/iter; left time: 110.9991s
	iters: 600, epoch: 4 | loss: 0.2144791
	speed: 0.0082s/iter; left time: 126.5027s
	iters: 700, epoch: 4 | loss: 0.2626782
	speed: 0.0080s/iter; left time: 121.4706s
	iters: 800, epoch: 4 | loss: 0.2686040
	speed: 0.0072s/iter; left time: 108.8435s
	iters: 900, epoch: 4 | loss: 0.3646030
	speed: 0.0077s/iter; left time: 115.1762s
	iters: 1000, epoch: 4 | loss: 0.3906246
	speed: 0.0069s/iter; left time: 102.7367s
	iters: 1100, epoch: 4 | loss: 0.5446162
	speed: 0.0067s/iter; left time: 100.0365s
	iters: 1200, epoch: 4 | loss: 0.6641119
	speed: 0.0061s/iter; left time: 89.8430s
	iters: 1300, epoch: 4 | loss: 0.4485032
	speed: 0.0067s/iter; left time: 97.4607s
	iters: 1400, epoch: 4 | loss: 0.5748140
	speed: 0.0066s/iter; left time: 95.4422s
	iters: 1500, epoch: 4 | loss: 0.5441968
	speed: 0.0066s/iter; left time: 94.7867s
	iters: 1600, epoch: 4 | loss: 0.3741358
	speed: 0.0073s/iter; left time: 105.3406s
	iters: 1700, epoch: 4 | loss: 0.3891205
	speed: 0.0066s/iter; left time: 93.4687s
	iters: 1800, epoch: 4 | loss: 0.3674568
	speed: 0.0066s/iter; left time: 92.8175s
	iters: 1900, epoch: 4 | loss: 0.2218055
	speed: 0.0062s/iter; left time: 87.7729s
	iters: 2000, epoch: 4 | loss: 0.1873415
	speed: 0.0064s/iter; left time: 89.3269s
	iters: 2100, epoch: 4 | loss: 0.4258266
	speed: 0.0067s/iter; left time: 93.0126s
	iters: 2200, epoch: 4 | loss: 0.3963563
	speed: 0.0067s/iter; left time: 92.3461s
Epoch: 4 cost time: 58.41537570953369
Epoch: 4, Steps: 2278 | Train Loss: 0.4509402 Vali Loss: 0.4247956 Test Loss: 0.1735325
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3230264
	speed: 1.4325s/iter; left time: 19437.5402s
	iters: 200, epoch: 5 | loss: 0.4278041
	speed: 0.0073s/iter; left time: 98.2179s
	iters: 300, epoch: 5 | loss: 0.3560771
	speed: 0.0068s/iter; left time: 91.1770s
	iters: 400, epoch: 5 | loss: 2.3684225
	speed: 0.0067s/iter; left time: 88.9074s
	iters: 500, epoch: 5 | loss: 0.3313713
	speed: 0.0071s/iter; left time: 93.4288s
	iters: 600, epoch: 5 | loss: 0.2593616
	speed: 0.0070s/iter; left time: 91.6144s
	iters: 700, epoch: 5 | loss: 0.2745598
	speed: 0.0073s/iter; left time: 94.8188s
	iters: 800, epoch: 5 | loss: 0.5107721
	speed: 0.0071s/iter; left time: 91.3191s
	iters: 900, epoch: 5 | loss: 0.3443248
	speed: 0.0072s/iter; left time: 91.7277s
	iters: 1000, epoch: 5 | loss: 2.1866050
	speed: 0.0065s/iter; left time: 82.6804s
	iters: 1100, epoch: 5 | loss: 0.5117548
	speed: 0.0066s/iter; left time: 83.1512s
	iters: 1200, epoch: 5 | loss: 0.4136196
	speed: 0.0064s/iter; left time: 80.3594s
	iters: 1300, epoch: 5 | loss: 0.3177624
	speed: 0.0067s/iter; left time: 83.0895s
	iters: 1400, epoch: 5 | loss: 0.6004026
	speed: 0.0074s/iter; left time: 90.5241s
	iters: 1500, epoch: 5 | loss: 0.4084227
	speed: 0.0083s/iter; left time: 100.7003s
	iters: 1600, epoch: 5 | loss: 0.1981670
	speed: 0.0073s/iter; left time: 87.6673s
	iters: 1700, epoch: 5 | loss: 0.3356127
	speed: 0.0074s/iter; left time: 88.6261s
	iters: 1800, epoch: 5 | loss: 2.3453617
	speed: 0.0073s/iter; left time: 86.6343s
	iters: 1900, epoch: 5 | loss: 0.4844432
	speed: 0.0084s/iter; left time: 98.3269s
	iters: 2000, epoch: 5 | loss: 0.4086958
	speed: 0.0075s/iter; left time: 88.0313s
	iters: 2100, epoch: 5 | loss: 0.2210964
	speed: 0.0092s/iter; left time: 106.4071s
	iters: 2200, epoch: 5 | loss: 0.2685975
	speed: 0.0083s/iter; left time: 95.0652s
Epoch: 5 cost time: 63.053539514541626
Epoch: 5, Steps: 2278 | Train Loss: 0.4507066 Vali Loss: 0.4254294 Test Loss: 0.1739026
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : weather_336_96_DLinear_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
mse:0.17559900879859924, mae:0.23700685799121857, rse:0.5521625876426697, corr:[0.4881952  0.48677465 0.48552847 0.4851496  0.48454395 0.48395574
 0.48277017 0.4820351  0.4813793  0.48040363 0.47942504 0.47901937
 0.4785285  0.47785404 0.4771711  0.47644964 0.47598186 0.47522154
 0.47444007 0.4739533  0.47337374 0.47253162 0.47193694 0.47113028
 0.47034293 0.46962753 0.4686458  0.4675568  0.46652666 0.4651844
 0.46421832 0.46328408 0.46233588 0.46124706 0.46043754 0.45949423
 0.4587548  0.4578074  0.45696792 0.45616043 0.45522913 0.4546817
 0.45413843 0.45333636 0.45252022 0.45190847 0.45115435 0.45067614
 0.4500617  0.44939008 0.44870666 0.4479192  0.44749713 0.44682455
 0.4463385  0.4458133  0.44553602 0.44469288 0.44394267 0.4436238
 0.4433821  0.4429704  0.4427203  0.44244534 0.442      0.4419014
 0.4416759  0.4415335  0.44129646 0.44138494 0.44096857 0.44078588
 0.4402161  0.4399927  0.43967754 0.4391624  0.4387796  0.438376
 0.43796936 0.43780512 0.43803367 0.43811437 0.43825653 0.43835783
 0.43830538 0.43829802 0.43836647 0.4382632  0.4379818  0.43768105
 0.4377513  0.43739215 0.43698394 0.4370817  0.43635476 0.43663806]
